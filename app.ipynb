{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@######################error rienvforenfv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.1' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "c:\\Users\\Dell\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.4' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [19/Jun/2024 22:54:31] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2024 22:54:36] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [19/Jun/2024 22:54:58] \"GET /Comics.html HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2024 22:55:08] \"GET /Recommendation.html HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2024 22:55:09] \"GET /Search.html HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2024 22:55:11] \"GET /Romance.html HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2024 22:55:36] \"GET /HOME.html HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2024 22:55:53] \"GET /Fantasy.html HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2024 22:55:56] \"GET /Self_help HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2024 22:56:19] \"GET /Romance.html HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2024 22:56:21] \"GET /Fantasy.html HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2024 22:56:29] \"GET /add_to_cart.html HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [19/Jun/2024 22:57:04] \"GET /order_data.json HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [19/Jun/2024 22:57:04] \"POST /add_to_cart.html HTTP/1.1\" 405 -\n",
      "127.0.0.1 - - [19/Jun/2024 22:57:20] \"GET /Search.html HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching Google search links: search() got an unexpected keyword argument 'num_results'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [19/Jun/2024 22:57:36] \"POST /Search.html HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['solo_leveling_image_0.png', 'solo_leveling_image_1.png', 'solo_leveling_image_2.png', 'solo_leveling_image_3.png']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [19/Jun/2024 23:02:09] \"GET /HOME.html HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import shutil\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from textblob import TextBlob\n",
    "from spellchecker import SpellChecker\n",
    "import nbformat\n",
    "from nbconvert import PythonExporter\n",
    "from flask import Flask, render_template, request\n",
    "import sys\n",
    "import subprocess\n",
    "from googlesearch import search\n",
    "\n",
    "\n",
    "app = Flask(__name__, template_folder=\"templates\", static_folder=\"static\")\n",
    "app.config[\"UPLOAD_FOLDER\"]=r\"static\"\n",
    "\n",
    "# Function to check and install missing libraries\n",
    "def install_missing_libraries():\n",
    "    required_libraries = [\n",
    "        \"wikipedia\",\n",
    "        \"textblob\",\n",
    "        \"spellchecker\",\n",
    "        \"requests\",\n",
    "        \"bs4\",\n",
    "        \"termcolor\",\n",
    "        \"Pillow\",\n",
    "        \"matplotlib\",\n",
    "        \"numpy\",\n",
    "        \"wikipedia\",\n",
    "        \"google\"\n",
    "    ]\n",
    "    missing_libraries = []\n",
    "    for lib in required_libraries:\n",
    "        try:\n",
    "            __import__(lib)\n",
    "        except ImportError:\n",
    "            missing_libraries.append(lib)\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", lib])\n",
    "    if missing_libraries:\n",
    "        print(\"Installed missing libraries:\", missing_libraries)\n",
    "    else:\n",
    "        print(\"All required libraries are installed.\")\n",
    "\n",
    "# Convert Jupyter Notebook cell to Python script\n",
    "def notebook_to_python(notebook_cell):\n",
    "    notebook_content = nbformat.v4.new_notebook(cells=[nbformat.v4.new_code_cell(notebook_cell)])\n",
    "    python_exporter = PythonExporter()\n",
    "    python_script, _ = python_exporter.from_notebook_node(notebook_content)\n",
    "    # Fix indentation and escape newline characters\n",
    "    python_script = python_script.replace('\\n', '\\\\n')\n",
    "    return python_script\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_input(user_input):\n",
    "    user_input = user_input.lower()  # Convert to lowercase\n",
    "    spell = SpellChecker()\n",
    "    tokens = TextBlob(user_input).words  # Tokenization\n",
    "    corrected_tokens = []\n",
    "    for token in tokens:\n",
    "        # Skip spelling correction for non-English words\n",
    "        if re.match(r'^[a-zA-Z]+$', token):\n",
    "            corrected_tokens.append(spell.correction(token))\n",
    "        else:\n",
    "            corrected_tokens.append(token)\n",
    "    return \" \".join(corrected_tokens)\n",
    "\n",
    "# Define search_book function\n",
    "def search_book(book_title, user_query):\n",
    "    import wikipedia\n",
    "    try:\n",
    "        page = wikipedia.page(book_title)\n",
    "        content = page.content\n",
    "        relevant_content = extract_relevant_content(content, user_query)\n",
    "        \n",
    "        # Extract multiple image URLs from Google Images\n",
    "        image_urls = fetch_image_urls(book_title, 4)  # Fetch four images\n",
    "        if not image_urls:\n",
    "            return \"Sorry, couldn't find any images for this book.\", None, None\n",
    "        \n",
    "        # Fetch top 3 Google search links\n",
    "        search_links = fetch_google_search_links(user_query, 3)\n",
    "        \n",
    "        import os\n",
    "\n",
    "        # Download the images and save them locally\n",
    "        image_paths = []\n",
    "        for i, url in enumerate(image_urls):\n",
    "            image_path = f\"{book_title.replace(' ', '_')}_image_{i}.png\"\n",
    "            response = requests.get(url, stream=True)\n",
    "            full_image_path = os.path.join(app.config[\"UPLOAD_FOLDER\"], image_path)\n",
    "            with open(full_image_path, 'wb') as out_file:\n",
    "                shutil.copyfileobj(response.raw, out_file)\n",
    "            image_paths.append(image_path)\n",
    "        \n",
    "        return relevant_content, image_paths, search_links\n",
    "    except wikipedia.exceptions.DisambiguationError as e:\n",
    "        return f\"Multiple results found. Please be more specific: {', '.join(e.options)}\", None, None\n",
    "    except wikipedia.exceptions.PageError:\n",
    "        return \"Sorry, I couldn't find any information about that book.\", None, None\n",
    "\n",
    "def extract_relevant_content(content, user_query):\n",
    "    relevant_content = \"\"\n",
    "    sections = re.split(r'\\n(?===)', content)  # Split content into sections\n",
    "    for section in sections:\n",
    "        if user_query.lower() in section.lower():\n",
    "            relevant_content += section + '\\n'\n",
    "    return relevant_content\n",
    "\n",
    "def fetch_image_urls(query, num_images):\n",
    "    try:\n",
    "        search_url = f\"https://www.google.com/search?q={query.replace(' ', '+')}+book+cover&tbm=isch\"\n",
    "        headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "        response = requests.get(search_url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        img_tags = soup.find_all('img')\n",
    "        # Extract URLs of the first 'num_images' images\n",
    "        image_urls = [img['src'] for img in img_tags[1:num_images+1]]\n",
    "        return image_urls\n",
    "    except Exception as e:\n",
    "        print(\"Error fetching image URLs:\", e)\n",
    "        return []\n",
    "\n",
    "def fetch_google_search_links(query, num_links):\n",
    "    try:\n",
    "        search_links = list(search(query, num_results=num_links, stop=num_links, pause=2))\n",
    "        return search_links\n",
    "    except Exception as e:\n",
    "        print(\"Error fetching Google search links:\", e)\n",
    "        return []\n",
    "\n",
    "# Notebook cell content converted to Python script\n",
    "notebook_cell = \"\"\"\n",
    "def preprocess_input(user_input):\n",
    "    user_input = user_input.lower()  # Convert to lowercase\n",
    "    spell = SpellChecker()\n",
    "    tokens = TextBlob(user_input).words  # Tokenization\n",
    "    corrected_tokens = []\n",
    "    for token in tokens:\n",
    "        # Skip spelling correction for non-English words\n",
    "        if re.match(r'^[a-zA-Z]+$', token):\n",
    "            corrected_tokens.append(spell.correction(token))\n",
    "        else:\n",
    "            corrected_tokens.append(token)\n",
    "    return \" \".join(corrected_tokens)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# Define the function to load pickled objects\n",
    "def load_pickled_objects():\n",
    "    with open(r'E:\\semsester 6\\WEB_PROGRAMMING_PROJECT\\recommend_book_function.pkl', 'rb') as f:\n",
    "        recommend_book = pickle.load(f)\n",
    "\n",
    "    with open(r'E:\\semsester 6\\WEB_PROGRAMMING_PROJECT\\knn_model.pkl', 'rb') as f:\n",
    "        knn_model = pickle.load(f)\n",
    "    \n",
    "    return recommend_book, knn_model\n",
    "\n",
    "\n",
    "# Define route for book recommendations\n",
    "@app.route('/Recommendation.html', methods=['GET', 'POST'])\n",
    "def recommendation():\n",
    "    if request.method == 'POST':\n",
    "        book_name = request.form['book_name']\n",
    "        recommendations = recommend_book(book_name)\n",
    "        return render_template('Recommendation.html', recommendations=recommendations)\n",
    "    return render_template('Recommendation.html', recommendations=None)\n",
    "\n",
    "\n",
    "def recommend_book(book_name):\n",
    "    # Load necessary data and models\n",
    "    corrected_books_df = pd.read_csv(r'C:\\Users\\Dell\\Downloads\\BX-Books-Corrected.csv', sep=';', encoding='latin-1')\n",
    "\n",
    "    # Check if 'title' column exists\n",
    "    if 'title' not in corrected_books_df.columns:\n",
    "        return \"Error: 'title' column not found in the DataFrame.\"\n",
    "\n",
    "    # Assuming knn_model is already loaded\n",
    "    matched_book_name = book_name.strip().lower()\n",
    "    if matched_book_name not in corrected_books_df['title'].str.lower().values:\n",
    "        return []  # Return an empty list if book not found\n",
    "\n",
    "    # Find recommendations based on similarity using knn_model\n",
    "    query_book = corrected_books_df[corrected_books_df['title'].str.lower() == matched_book_name]\n",
    "    query_features = query_book[['year', 'publisher']]  # Assuming 'year' and 'publisher' are used for similarity\n",
    "\n",
    "    distances, indices = knn_model.kneighbors(query_features, n_neighbors=6)\n",
    "\n",
    "    recommendations = []\n",
    "    for i in range(1, len(distances.flatten())):\n",
    "        recommended_book_index = indices.flatten()[i]\n",
    "        recommended_book = corrected_books_df.iloc[recommended_book_index]\n",
    "        recommendations.append(recommended_book)\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('HOME.html')\n",
    "\n",
    "\n",
    "@app.route('/HOME.html')\n",
    "def home2():\n",
    "    return render_template('HOME.html')\n",
    "@app.route('/Self_help')\n",
    "def self_help():\n",
    "    return render_template('Self_help.html')\n",
    "\n",
    "@app.route('/Romance.html')\n",
    "def romance():\n",
    "    return render_template('Romance.html')\n",
    "\n",
    "@app.route('/Fantasy.html')\n",
    "def fantasy():\n",
    "    return render_template('Fantasy.html')\n",
    "\n",
    "@app.route('/Comics.html')\n",
    "def comics():\n",
    "    return render_template('Comics.html')\n",
    "\n",
    "@app.route('/add_to_cart.html')\n",
    "def add_to_cart():\n",
    "    return render_template('add_to_cart.html')\n",
    "\n",
    "@app.route('/Search.html', methods=['GET', 'POST'])\n",
    "def search():\n",
    "    if request.method == 'POST':\n",
    "        user_input = request.form['user_input']\n",
    "        # Convert Jupyter Notebook cell to Python script\n",
    "        python_script = notebook_to_python(notebook_cell)\n",
    "        # Execute the Python script in the same environment\n",
    "        exec(python_script)\n",
    "        preprocessed_input = preprocess_input(user_input)\n",
    "        response, images, search_links = search_book(preprocessed_input, user_input)\n",
    "        print(images)\n",
    "        return render_template('Search.html', response=response, images=images, search_links=search_links)\n",
    "    return render_template('Search.html')\n",
    "\n",
    "\n",
    "# Main block to run the app\n",
    "if __name__ == '__main__':\n",
    "    recommend_book, knn_model = load_pickled_objects()\n",
    "    app.run(debug=True, use_reloader=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
